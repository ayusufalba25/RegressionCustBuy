---
title: "Purchasing Decisions for Customers at Dapur Putih Cafe Metro"
output: html_notebook
---

This project inspired from a thesis called "Pengaruh Tingkat Harga dan Kualitas Produk Terhadap Keputusan Pembelian bagi Konsumen di Dapur Putih Cafe Metro" by Nella Fanitawati in 2020. The data used is also from the thesis itself. The data was generated by Nella Fanitawati from her survey using a questionnaire with a random sampling technique for customers at Dapur Putih Cafe. There are **53 respondents** in the survey.

Dapur Putih Cafe is one of the places to eat in the Metro City that offers food and drinks as well as a comfortable place to hang out. It also offered affordable prices for its products.

The main problem statement was: **How to analyze the influence of the price level and product quality on customer decisions to buy Daput Putih Cafe's products?**

To answer that, we can fit a linear regression model and check if the beta coefficient for its independent variables is significant or not.

```{r}
# Import libraries
library(tidyverse)
library(readxl)
library(skimr)
library(lmtest)
library(psych)
```

```{r}
# Import data
df <- read_xlsx("Dapur Putih Cafe.xlsx")
df
```

There are three variables in the dataset which are consider_buying, price, and product_quality. The dependent variable in this dataset is consider_buying and the remaining variables are the independent variables. Below is the description of each of those variables:

- consider_buying: a condition in which customers decide whether to buy the Dapur Putih Cafe products or not.
- price: the price of products in Dapur Putih Cafe that is based on the affordability of the given prices and the value.
- product_quality: The quality of products in Dapur Putih Cafe.

The values of each variable lie within 5-25 as integers (no decimals). But, we could treat it as a continuous value in regression.

```{r}
# Skim the data
skim(df)
```

After we skim the data, we can see some metrics and a histogram for each variable. As you can see product_quality has the highest mean and median compared to the other variables. It means that the quality of products in Dapur Putih Cafe is reasonably high compared to its prices.

Furthermore, we need to check if there is any clear patterns that shown a relationship between each independent variables on its dependent variable. We can create scatterplots and calculate its spearman correlation coefficient (spearman correlation used cause it does not have assumption about the distribution of the data).

```{r}
# Check if there is any clear of relationship pattern
pairs.panels(df, method = "spearman")
```

From the plot above, we can see that our dependent variable has a higher correlation coefficient with price rather than product_quality. Therefore, we could conclude that customers have a greater chance to buy Dapur Putih Cafe's products because it has affordable prices.

Before we get into modeling, we need to check of there is any outlier in the data based on each of its variable. We can use boxplot to visualize and check the outliers.

```{r}
# Check if there is any outliers in the data using boxplot
par(mfrow = c(1, 3))
boxplot(df$consider_buying)
boxplot(df$price)
boxplot(df$product_quality)
```
From each of the boxplot we can see that there is no outliers in the data. Then, we could prepare the data for modeling by splitting the data randomly into training and test set with 90:10 ratios.

```{r}
# Split the data into train and test set
set.seed(123)
train_set = sample(1:nrow(df), round(0.9 * nrow(df), 0))
df_train <- df[train_set,]
df_test <- df[-train_set,]
```

Then, we fit the data using linear regression.

```{r}
# Fitting linear regression model
model <- lm(consider_buying ~ ., data = df_train)
summary(model)
```

We use 5% significance level in our hypothesis testing for the inference in the regression modeling. Unfortunately, we can see that our independent variables is not simultaneously significant. It is shown from the p-value of F-statistic that is 0.09043 and it is less than the 5% significance level. Therefore, we cannot solve the main problem statement based on our independent variables.

For each of the regression coefficient (beta), we can see that product_quality is the only one that does not have significant effect on the dependent variable. It is based on its p-value (Pr>|t|) with 0.71261 that less than 5% significance level. We can remove this independent variable from to get the best model for our problem.

Furthermore, we can see that our model has R-squared with 10.13% and it is relatively low. It could be solved by adding mode independent variables in the linear regression model. But, in this experiment there are only two independent variables that we could use for modeling. Maybe, the researcher should consider to add more independent variables that could explain the costumer consideration in the experiment to decide whether they want to buy the products of Dapur Putih Cafe or not. The investigation to add more independent variables could be done by studying more pieces of literature to get a better understanding for deciding which independent variables she could use.

Then, we need to remove product_quality from the model and fit the linear regression model once again.

```{r}
# Fitting linear regression model but without product_quality
model <- lm(consider_buying ~ price, data = df_train)
summary(model)
```

The adjusted R-squared from the evaluated model is higher than the initial model that has product_quality as its second independent variable. The R-squared is also has a relatively the same value, it just drop from 10.13% to 10.11%. Therefore, we can conclude that our that our evaluated model is better than the initial model.

After that, we can check if our model is valid by checking if the assumption is already fulfilled. There are two main assumption that we need to check which are the normality of the residual and the homoscedasticity of its residual variance.


```{r}
# Model assumption checking

# Normality test for residual
shapiro.test(model$residuals)

# Heteroscedasticity test
bptest(model)
```

From both of the Shapiro-Wilk and Breusch-Pagan test we can conclude that our model is valid. The model's residuals has normal distribution and its variance is homoscedastic. It is shown by the p-value of each test that is greater than 5% significance level.

Therefore, we can generate insights from the model by interpreting its regression coefficient. From the model, we can conclude that price has a significant effect on consider_buying as its dependent variable with a 0.2744 coefficient value. From its coefficient value, the price has a positive effect on consider_buying. It means that the more value and affordable the prices are than the customer is likely to buy products from Dapur Putih Cafe.

Next, we need to calculate our model's prediction performance using Root Mean Squared Error (RMSE) and Mean Absolute Percentage Error (MAPE) for the test set.

```{r}
# Prediction performance

# Predict test data
y_test_pred <- predict(model, df_test[-1])

# RMSE
rmse <- function(y_true, y_pred){
  mse <- mean((y_true - y_pred) ^ 2)
  return(sqrt(mse))
}
cat("RMSE =", rmse(df_test$consider_buying, y_test_pred), "\n")

# MAPE
mape <- function(y_true, y_pred){
  return((mean(abs(y_true - y_pred) / y_true) * 100))
}
cat("MAPE =", mape(df_test$consider_buying, y_test_pred))
```

Our model has good performance for predicting the customer consideration to buy the Dapur Putih Cafe's products from its prices (affordability and value). RMSE and MAPE that we have got are 1.197779 and 5.774701 respectively.


```{r}
# Clustering customers
cluster_customer <- kmeans(df[-3], 2)
cluster_customer
```

```{r}
# Add a column to store cluster
df <- df %>% select(-product_quality) %>% mutate(cluster = cluster_customer$cluster)
df
```


```{r}
# Create a plot to visualize the cluster
ggplot(df, aes(price, consider_buying)) +
  geom_point(aes(colour = cut(cluster, c(-Inf, 1.5, Inf)))) +
  scale_color_manual(name = "Cluster",
                     values = c("(-Inf,1.5]" = "black",
                                  "(1.5, Inf]" = "red"),
                     labels = c("Cluster 1", "Cluster 2"))
```


